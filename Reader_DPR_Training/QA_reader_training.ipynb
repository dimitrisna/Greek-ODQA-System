{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Reader Training\n",
        "\n",
        "Installing all the necessary dependences for fine-tuning a BERT model for Question Answering with the use of TPU."
      ],
      "metadata": {
        "id": "T5rsizXvmVH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RvRp-N7YaYs"
      },
      "outputs": [],
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P6b3uqfzpDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42avAvSg17by",
        "outputId": "147acacb-9219-40f8-f902-6ecf43749719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.11...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.11...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.11\n"
          ]
        }
      ],
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3PyI7E6ZkkE",
        "outputId": "04464879-fa06-4d67-df0d-751a9e9f1154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 99374, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 99374 (delta 99), reused 130 (delta 63), pack-reused 99151\u001b[K\n",
            "Receiving objects: 100% (99374/99374), 92.95 MiB | 22.27 MiB/s, done.\n",
            "Resolving deltas: 100% (73186/73186), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LFlWikpZmtd",
        "outputId": "9415a661-db24-4ff4-a62c-8467d42341ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers/examples/pytorch/question-answering\n"
          ]
        }
      ],
      "source": [
        "cd transformers/examples/pytorch/question-answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Xnds-SZpyi",
        "outputId": "363308e4-ce55-4d56-f53f-a51b28d3be55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install git-lfs\n",
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chj7wXpSZtLU"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the HuggingFace script for fine-tuning BERT for Question Answering. More information about the script can be found in https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa.py"
      ],
      "metadata": {
        "id": "aDb3dj6v4tnI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usy6bXJFZ4kT",
        "outputId": "6f22d7a5-67c1-4815-fb62-83b6b82f12ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.11\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/training_args.py:1157: FutureWarning: using `--tpu_metrics_debug` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--debug tpu_metrics_debug` instead\n",
            "  FutureWarning,\n",
            "WARNING:__main__:Process rank: -1, device: xla:1, n_gpu: 0distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=0,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[<DebugOption.TPU_METRICS_DEBUG: 'tpu_metrics_debug'>],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/nq_squad_bert_el17/runs/Jun20_00-23-07_2b296ad42131,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/drive/MyDrive/nq_squad_bert_el17,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=24,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/nq_squad_bert_el17,\n",
            "save_on_each_node=False,\n",
            "save_steps=10000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "WARNING:datasets.builder:Using custom data configuration Danastos--squad_nq_el-6ce17c992b694ab3\n",
            "INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/Danastos___json/Danastos--squad_nq_el-6ce17c992b694ab3/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n",
            "Downloading and preparing dataset json/Danastos--squad_nq_el to /root/.cache/huggingface/datasets/Danastos___json/Danastos--squad_nq_el-6ce17c992b694ab3/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5...\n",
            "INFO:datasets.builder:Dataset not on Hf google storage. Downloading and preparing it from source\n",
            "Downloading data files:   0% 0/2 [00:00<?, ?it/s]INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Danastos/squad_nq_el/resolve/ed53f7dac280ac5f44473a34c2773e89896a0d6a/nq_squad_train.jsonl not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpclzfffe8\n",
            "\n",
            "Downloading data:   0% 0.00/863M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0% 3.47M/863M [00:00<00:24, 34.7MB/s]\u001b[A\n",
            "Downloading data:   1% 9.74M/863M [00:00<00:16, 51.2MB/s]\u001b[A\n",
            "Downloading data:   2% 15.1M/863M [00:00<00:16, 52.2MB/s]\u001b[A\n",
            "Downloading data:   2% 21.0M/863M [00:00<00:15, 55.1MB/s]\u001b[A\n",
            "Downloading data:   3% 27.4M/863M [00:00<00:14, 58.0MB/s]\u001b[A\n",
            "Downloading data:   4% 33.3M/863M [00:00<00:14, 58.4MB/s]\u001b[A\n",
            "Downloading data:   5% 39.1M/863M [00:00<00:14, 58.0MB/s]\u001b[A\n",
            "Downloading data:   5% 45.5M/863M [00:00<00:13, 59.9MB/s]\u001b[A\n",
            "Downloading data:   6% 51.7M/863M [00:00<00:13, 60.4MB/s]\u001b[A\n",
            "Downloading data:   7% 57.7M/863M [00:01<00:13, 59.1MB/s]\u001b[A\n",
            "Downloading data:   7% 63.8M/863M [00:01<00:13, 59.7MB/s]\u001b[A\n",
            "Downloading data:   8% 69.8M/863M [00:01<00:13, 59.9MB/s]\u001b[A\n",
            "Downloading data:   9% 75.8M/863M [00:01<00:13, 58.3MB/s]\u001b[A\n",
            "Downloading data:  10% 82.1M/863M [00:01<00:13, 59.6MB/s]\u001b[A\n",
            "Downloading data:  10% 88.3M/863M [00:01<00:12, 60.2MB/s]\u001b[A\n",
            "Downloading data:  11% 94.3M/863M [00:01<00:12, 60.0MB/s]\u001b[A\n",
            "Downloading data:  12% 100M/863M [00:01<00:12, 60.4MB/s] \u001b[A\n",
            "Downloading data:  12% 106M/863M [00:01<00:12, 59.5MB/s]\u001b[A\n",
            "Downloading data:  13% 112M/863M [00:01<00:13, 57.0MB/s]\u001b[A\n",
            "Downloading data:  14% 118M/863M [00:02<00:16, 44.3MB/s]\u001b[A\n",
            "Downloading data:  14% 124M/863M [00:02<00:15, 47.6MB/s]\u001b[A\n",
            "Downloading data:  15% 129M/863M [00:02<00:15, 48.1MB/s]\u001b[A\n",
            "Downloading data:  16% 134M/863M [00:02<00:14, 49.2MB/s]\u001b[A\n",
            "Downloading data:  16% 140M/863M [00:02<00:14, 51.5MB/s]\u001b[A\n",
            "Downloading data:  17% 145M/863M [00:02<00:13, 52.0MB/s]\u001b[A\n",
            "Downloading data:  18% 151M/863M [00:02<00:13, 53.1MB/s]\u001b[A\n",
            "Downloading data:  18% 156M/863M [00:02<00:13, 53.2MB/s]\u001b[A\n",
            "Downloading data:  19% 162M/863M [00:02<00:12, 55.0MB/s]\u001b[A\n",
            "Downloading data:  19% 168M/863M [00:03<00:12, 55.7MB/s]\u001b[A\n",
            "Downloading data:  20% 174M/863M [00:03<00:12, 56.1MB/s]\u001b[A\n",
            "Downloading data:  21% 179M/863M [00:03<00:12, 56.1MB/s]\u001b[A\n",
            "Downloading data:  21% 185M/863M [00:03<00:12, 55.4MB/s]\u001b[A\n",
            "Downloading data:  22% 191M/863M [00:03<00:12, 55.9MB/s]\u001b[A\n",
            "Downloading data:  23% 196M/863M [00:03<00:11, 56.2MB/s]\u001b[A\n",
            "Downloading data:  24% 203M/863M [00:03<00:11, 58.1MB/s]\u001b[A\n",
            "Downloading data:  24% 209M/863M [00:03<00:11, 58.1MB/s]\u001b[A\n",
            "Downloading data:  25% 215M/863M [00:03<00:10, 59.3MB/s]\u001b[A\n",
            "Downloading data:  26% 221M/863M [00:03<00:10, 59.5MB/s]\u001b[A\n",
            "Downloading data:  26% 227M/863M [00:04<00:10, 59.4MB/s]\u001b[A\n",
            "Downloading data:  27% 233M/863M [00:04<00:10, 61.0MB/s]\u001b[A\n",
            "Downloading data:  28% 239M/863M [00:04<00:10, 61.1MB/s]\u001b[A\n",
            "Downloading data:  28% 245M/863M [00:04<00:10, 57.5MB/s]\u001b[A\n",
            "Downloading data:  29% 252M/863M [00:04<00:10, 59.0MB/s]\u001b[A\n",
            "Downloading data:  30% 258M/863M [00:04<00:10, 59.6MB/s]\u001b[A\n",
            "Downloading data:  31% 264M/863M [00:04<00:10, 58.4MB/s]\u001b[A\n",
            "Downloading data:  31% 270M/863M [00:04<00:10, 58.8MB/s]\u001b[A\n",
            "Downloading data:  32% 276M/863M [00:04<00:11, 49.5MB/s]\u001b[A\n",
            "Downloading data:  33% 281M/863M [00:05<00:11, 51.5MB/s]\u001b[A\n",
            "Downloading data:  33% 287M/863M [00:05<00:10, 54.1MB/s]\u001b[A\n",
            "Downloading data:  34% 293M/863M [00:05<00:10, 54.8MB/s]\u001b[A\n",
            "Downloading data:  35% 299M/863M [00:05<00:10, 55.8MB/s]\u001b[A\n",
            "Downloading data:  35% 305M/863M [00:05<00:10, 54.5MB/s]\u001b[A\n",
            "Downloading data:  36% 311M/863M [00:05<00:09, 55.7MB/s]\u001b[A\n",
            "Downloading data:  37% 316M/863M [00:05<00:09, 56.1MB/s]\u001b[A\n",
            "Downloading data:  37% 322M/863M [00:05<00:09, 56.0MB/s]\u001b[A\n",
            "Downloading data:  38% 328M/863M [00:05<00:09, 56.4MB/s]\u001b[A\n",
            "Downloading data:  39% 333M/863M [00:05<00:09, 54.1MB/s]\u001b[A\n",
            "Downloading data:  39% 339M/863M [00:06<00:09, 54.6MB/s]\u001b[A\n",
            "Downloading data:  40% 345M/863M [00:06<00:09, 56.1MB/s]\u001b[A\n",
            "Downloading data:  41% 351M/863M [00:06<00:08, 58.6MB/s]\u001b[A\n",
            "Downloading data:  41% 357M/863M [00:06<00:09, 55.4MB/s]\u001b[A\n",
            "Downloading data:  42% 363M/863M [00:06<00:08, 57.0MB/s]\u001b[A\n",
            "Downloading data:  43% 369M/863M [00:06<00:08, 57.7MB/s]\u001b[A\n",
            "Downloading data:  43% 375M/863M [00:06<00:08, 58.0MB/s]\u001b[A\n",
            "Downloading data:  44% 381M/863M [00:06<00:08, 59.5MB/s]\u001b[A\n",
            "Downloading data:  45% 388M/863M [00:06<00:07, 60.8MB/s]\u001b[A\n",
            "Downloading data:  46% 394M/863M [00:07<00:08, 58.5MB/s]\u001b[A\n",
            "Downloading data:  46% 400M/863M [00:07<00:07, 59.8MB/s]\u001b[A\n",
            "Downloading data:  47% 407M/863M [00:07<00:07, 61.2MB/s]\u001b[A\n",
            "Downloading data:  48% 413M/863M [00:07<00:07, 60.9MB/s]\u001b[A\n",
            "Downloading data:  49% 419M/863M [00:07<00:07, 58.5MB/s]\u001b[A\n",
            "Downloading data:  49% 425M/863M [00:07<00:07, 57.7MB/s]\u001b[A\n",
            "Downloading data:  50% 431M/863M [00:07<00:07, 54.3MB/s]\u001b[A\n",
            "Downloading data:  51% 436M/863M [00:07<00:08, 47.7MB/s]\u001b[A\n",
            "Downloading data:  51% 442M/863M [00:07<00:08, 50.1MB/s]\u001b[A\n",
            "Downloading data:  52% 447M/863M [00:07<00:08, 51.1MB/s]\u001b[A\n",
            "Downloading data:  52% 453M/863M [00:08<00:07, 52.7MB/s]\u001b[A\n",
            "Downloading data:  53% 459M/863M [00:08<00:07, 55.0MB/s]\u001b[A\n",
            "Downloading data:  54% 465M/863M [00:08<00:07, 55.9MB/s]\u001b[A\n",
            "Downloading data:  55% 470M/863M [00:08<00:06, 56.6MB/s]\u001b[A\n",
            "Downloading data:  55% 476M/863M [00:08<00:06, 55.7MB/s]\u001b[A\n",
            "Downloading data:  56% 482M/863M [00:08<00:06, 57.7MB/s]\u001b[A\n",
            "Downloading data:  57% 488M/863M [00:08<00:06, 58.1MB/s]\u001b[A\n",
            "Downloading data:  57% 495M/863M [00:08<00:06, 59.5MB/s]\u001b[A\n",
            "Downloading data:  58% 501M/863M [00:08<00:06, 59.9MB/s]\u001b[A\n",
            "Downloading data:  59% 507M/863M [00:09<00:06, 59.0MB/s]\u001b[A\n",
            "Downloading data:  59% 513M/863M [00:09<00:05, 60.6MB/s]\u001b[A\n",
            "Downloading data:  60% 519M/863M [00:09<00:05, 60.6MB/s]\u001b[A\n",
            "Downloading data:  61% 525M/863M [00:09<00:05, 58.4MB/s]\u001b[A\n",
            "Downloading data:  62% 531M/863M [00:09<00:05, 59.3MB/s]\u001b[A\n",
            "Downloading data:  62% 537M/863M [00:09<00:05, 59.3MB/s]\u001b[A\n",
            "Downloading data:  63% 544M/863M [00:09<00:05, 60.1MB/s]\u001b[A\n",
            "Downloading data:  64% 550M/863M [00:09<00:05, 60.5MB/s]\u001b[A\n",
            "Downloading data:  64% 556M/863M [00:09<00:04, 61.9MB/s]\u001b[A\n",
            "Downloading data:  65% 562M/863M [00:09<00:04, 61.6MB/s]\u001b[A\n",
            "Downloading data:  66% 569M/863M [00:10<00:05, 51.4MB/s]\u001b[A\n",
            "Downloading data:  67% 574M/863M [00:10<00:05, 52.2MB/s]\u001b[A\n",
            "Downloading data:  67% 580M/863M [00:10<00:05, 54.1MB/s]\u001b[A\n",
            "Downloading data:  68% 586M/863M [00:10<00:04, 55.3MB/s]\u001b[A\n",
            "Downloading data:  69% 592M/863M [00:10<00:05, 51.3MB/s]\u001b[A\n",
            "Downloading data:  69% 597M/863M [00:10<00:05, 50.9MB/s]\u001b[A\n",
            "Downloading data:  70% 602M/863M [00:10<00:04, 52.2MB/s]\u001b[A\n",
            "Downloading data:  70% 608M/863M [00:10<00:04, 52.7MB/s]\u001b[A\n",
            "Downloading data:  71% 613M/863M [00:10<00:04, 53.6MB/s]\u001b[A\n",
            "Downloading data:  72% 619M/863M [00:11<00:04, 54.4MB/s]\u001b[A\n",
            "Downloading data:  72% 625M/863M [00:11<00:04, 54.7MB/s]\u001b[A\n",
            "Downloading data:  73% 630M/863M [00:11<00:05, 38.9MB/s]\u001b[A\n",
            "Downloading data:  74% 636M/863M [00:11<00:05, 42.8MB/s]\u001b[A\n",
            "Downloading data:  74% 641M/863M [00:11<00:04, 44.9MB/s]\u001b[A\n",
            "Downloading data:  75% 647M/863M [00:11<00:04, 49.4MB/s]\u001b[A\n",
            "Downloading data:  76% 653M/863M [00:11<00:04, 52.1MB/s]\u001b[A\n",
            "Downloading data:  76% 659M/863M [00:11<00:03, 54.2MB/s]\u001b[A\n",
            "Downloading data:  77% 665M/863M [00:11<00:03, 56.7MB/s]\u001b[A\n",
            "Downloading data:  78% 671M/863M [00:12<00:03, 57.6MB/s]\u001b[A\n",
            "Downloading data:  79% 677M/863M [00:12<00:03, 58.3MB/s]\u001b[A\n",
            "Downloading data:  79% 683M/863M [00:12<00:03, 59.0MB/s]\u001b[A\n",
            "Downloading data:  80% 689M/863M [00:12<00:02, 58.6MB/s]\u001b[A\n",
            "Downloading data:  81% 695M/863M [00:12<00:02, 59.2MB/s]\u001b[A\n",
            "Downloading data:  81% 701M/863M [00:12<00:02, 57.3MB/s]\u001b[A\n",
            "Downloading data:  82% 707M/863M [00:12<00:02, 57.8MB/s]\u001b[A\n",
            "Downloading data:  83% 713M/863M [00:12<00:02, 57.4MB/s]\u001b[A\n",
            "Downloading data:  83% 719M/863M [00:12<00:02, 58.4MB/s]\u001b[A\n",
            "Downloading data:  84% 725M/863M [00:13<00:02, 53.7MB/s]\u001b[A\n",
            "Downloading data:  85% 730M/863M [00:13<00:02, 45.1MB/s]\u001b[A\n",
            "Downloading data:  85% 736M/863M [00:13<00:02, 48.7MB/s]\u001b[A\n",
            "Downloading data:  86% 742M/863M [00:13<00:02, 51.4MB/s]\u001b[A\n",
            "Downloading data:  87% 748M/863M [00:13<00:02, 53.2MB/s]\u001b[A\n",
            "Downloading data:  87% 753M/863M [00:13<00:02, 53.1MB/s]\u001b[A\n",
            "Downloading data:  88% 759M/863M [00:13<00:01, 53.9MB/s]\u001b[A\n",
            "Downloading data:  89% 764M/863M [00:13<00:01, 54.1MB/s]\u001b[A\n",
            "Downloading data:  89% 770M/863M [00:13<00:01, 55.0MB/s]\u001b[A\n",
            "Downloading data:  90% 776M/863M [00:13<00:01, 57.0MB/s]\u001b[A\n",
            "Downloading data:  91% 782M/863M [00:14<00:01, 57.0MB/s]\u001b[A\n",
            "Downloading data:  91% 788M/863M [00:14<00:01, 57.8MB/s]\u001b[A\n",
            "Downloading data:  92% 794M/863M [00:14<00:01, 59.5MB/s]\u001b[A\n",
            "Downloading data:  93% 800M/863M [00:14<00:01, 59.0MB/s]\u001b[A\n",
            "Downloading data:  93% 806M/863M [00:14<00:00, 59.3MB/s]\u001b[A\n",
            "Downloading data:  94% 812M/863M [00:14<00:00, 59.7MB/s]\u001b[A\n",
            "Downloading data:  95% 818M/863M [00:14<00:00, 56.4MB/s]\u001b[A\n",
            "Downloading data:  96% 824M/863M [00:14<00:00, 57.5MB/s]\u001b[A\n",
            "Downloading data:  96% 830M/863M [00:14<00:00, 56.2MB/s]\u001b[A\n",
            "Downloading data:  97% 836M/863M [00:15<00:00, 56.6MB/s]\u001b[A\n",
            "Downloading data:  98% 842M/863M [00:15<00:00, 55.8MB/s]\u001b[A\n",
            "Downloading data:  98% 847M/863M [00:15<00:00, 55.4MB/s]\u001b[A\n",
            "Downloading data:  99% 853M/863M [00:15<00:00, 57.4MB/s]\u001b[A\n",
            "Downloading data: 100% 863M/863M [00:15<00:00, 55.4MB/s]\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Danastos/squad_nq_el/resolve/ed53f7dac280ac5f44473a34c2773e89896a0d6a/nq_squad_train.jsonl in cache at /root/.cache/huggingface/datasets/downloads/9457a7359213b1e4421f075340d08a7918fbdac4bf3cd40e104860ffe809b1d2\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/9457a7359213b1e4421f075340d08a7918fbdac4bf3cd40e104860ffe809b1d2\n",
            "Downloading data files:  50% 1/2 [00:16<00:16, 16.02s/it]INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Danastos/squad_nq_el/resolve/ed53f7dac280ac5f44473a34c2773e89896a0d6a/nq_squad_dev.jsonl not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp74yieh0w\n",
            "\n",
            "Downloading data:   0% 0.00/65.3M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   6% 3.62M/65.3M [00:00<00:01, 36.2MB/s]\u001b[A\n",
            "Downloading data:  12% 7.74M/65.3M [00:00<00:01, 39.1MB/s]\u001b[A\n",
            "Downloading data:  18% 11.8M/65.3M [00:00<00:01, 39.7MB/s]\u001b[A\n",
            "Downloading data:  26% 17.1M/65.3M [00:00<00:01, 44.9MB/s]\u001b[A\n",
            "Downloading data:  34% 22.5M/65.3M [00:00<00:00, 48.2MB/s]\u001b[A\n",
            "Downloading data:  43% 27.8M/65.3M [00:00<00:00, 49.9MB/s]\u001b[A\n",
            "Downloading data:  51% 33.2M/65.3M [00:00<00:00, 51.1MB/s]\u001b[A\n",
            "Downloading data:  59% 38.3M/65.3M [00:00<00:00, 50.6MB/s]\u001b[A\n",
            "Downloading data:  68% 44.2M/65.3M [00:00<00:00, 53.2MB/s]\u001b[A\n",
            "Downloading data:  76% 49.5M/65.3M [00:01<00:00, 52.1MB/s]\u001b[A\n",
            "Downloading data:  85% 55.6M/65.3M [00:01<00:00, 54.9MB/s]\u001b[A\n",
            "Downloading data: 100% 65.3M/65.3M [00:01<00:00, 51.5MB/s]\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Danastos/squad_nq_el/resolve/ed53f7dac280ac5f44473a34c2773e89896a0d6a/nq_squad_dev.jsonl in cache at /root/.cache/huggingface/datasets/downloads/c68986610f30cbf5e428b197b1261f52ef8def2c353f98b9d899835a2b8f04a5\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/c68986610f30cbf5e428b197b1261f52ef8def2c353f98b9d899835a2b8f04a5\n",
            "Downloading data files: 100% 2/2 [00:17<00:00,  8.84s/it]\n",
            "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 782.67it/s]\n",
            "INFO:datasets.utils.info_utils:Unable to verify checksums.\n",
            "INFO:datasets.builder:Generating train split\n",
            "INFO:datasets.builder:Generating validation split\n",
            "INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/Danastos___json/Danastos--squad_nq_el-6ce17c992b694ab3/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 21.60it/s]\n",
            "[INFO|hub.py:592] 2022-06-20 00:23:47,519 >> https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqblb_pfn\n",
            "Downloading: 100% 459/459 [00:00<00:00, 290kB/s]\n",
            "[INFO|hub.py:596] 2022-06-20 00:23:47,664 >> storing https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/020dab34d496eb711abcd1a2fcb98999e8e52a647a19a30d587ecf0dced64b4d.3c398df2e83e354046a333f011627deb67111e36b02711ab77c2f4004a414da9\n",
            "[INFO|hub.py:604] 2022-06-20 00:23:47,664 >> creating metadata file for /root/.cache/huggingface/transformers/020dab34d496eb711abcd1a2fcb98999e8e52a647a19a30d587ecf0dced64b4d.3c398df2e83e354046a333f011627deb67111e36b02711ab77c2f4004a414da9\n",
            "[INFO|configuration_utils.py:659] 2022-06-20 00:23:47,665 >> loading configuration file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/020dab34d496eb711abcd1a2fcb98999e8e52a647a19a30d587ecf0dced64b4d.3c398df2e83e354046a333f011627deb67111e36b02711ab77c2f4004a414da9\n",
            "[INFO|configuration_utils.py:708] 2022-06-20 00:23:47,669 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlpaueb/bert-base-greek-uncased-v1\",\n",
            "  \"architectures\": [\n",
            "    \"BertForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 35000\n",
            "}\n",
            "\n",
            "[INFO|hub.py:592] 2022-06-20 00:23:47,802 >> https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8alwg3c6\n",
            "Downloading: 100% 2.00/2.00 [00:00<00:00, 1.33kB/s]\n",
            "[INFO|hub.py:596] 2022-06-20 00:23:47,937 >> storing https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/8bc519ac7a17e04e2e2de1908d5c2670888449f1489da619329762a3b21f6eb9.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|hub.py:604] 2022-06-20 00:23:47,937 >> creating metadata file for /root/.cache/huggingface/transformers/8bc519ac7a17e04e2e2de1908d5c2670888449f1489da619329762a3b21f6eb9.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|configuration_utils.py:659] 2022-06-20 00:23:48,083 >> loading configuration file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/020dab34d496eb711abcd1a2fcb98999e8e52a647a19a30d587ecf0dced64b4d.3c398df2e83e354046a333f011627deb67111e36b02711ab77c2f4004a414da9\n",
            "[INFO|configuration_utils.py:708] 2022-06-20 00:23:48,084 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlpaueb/bert-base-greek-uncased-v1\",\n",
            "  \"architectures\": [\n",
            "    \"BertForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 35000\n",
            "}\n",
            "\n",
            "[INFO|hub.py:592] 2022-06-20 00:23:48,368 >> https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpbi5w5zx6\n",
            "Downloading: 100% 518k/518k [00:00<00:00, 3.36MB/s]\n",
            "[INFO|hub.py:596] 2022-06-20 00:23:48,686 >> storing https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/36a03508d333d6195f8f456e8bcdebf6c61af8792f946a34b08a4ee5d7c0f86d.4157123280ff09762137030a9b558fcd76bd138c8e0275b9088621f0c807fbf5\n",
            "[INFO|hub.py:604] 2022-06-20 00:23:48,686 >> creating metadata file for /root/.cache/huggingface/transformers/36a03508d333d6195f8f456e8bcdebf6c61af8792f946a34b08a4ee5d7c0f86d.4157123280ff09762137030a9b558fcd76bd138c8e0275b9088621f0c807fbf5\n",
            "[INFO|hub.py:592] 2022-06-20 00:23:49,111 >> https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_5wk9q9k\n",
            "Downloading: 100% 112/112 [00:00<00:00, 58.3kB/s]\n",
            "[INFO|hub.py:596] 2022-06-20 00:23:49,274 >> storing https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/347c648cda48ba9d519777e5e1e677a659862faeb5ad9e219ff0a95c62cfdea4.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|hub.py:604] 2022-06-20 00:23:49,274 >> creating metadata file for /root/.cache/huggingface/transformers/347c648cda48ba9d519777e5e1e677a659862faeb5ad9e219ff0a95c62cfdea4.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1781] 2022-06-20 00:23:49,427 >> loading file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/36a03508d333d6195f8f456e8bcdebf6c61af8792f946a34b08a4ee5d7c0f86d.4157123280ff09762137030a9b558fcd76bd138c8e0275b9088621f0c807fbf5\n",
            "[INFO|tokenization_utils_base.py:1781] 2022-06-20 00:23:49,427 >> loading file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1781] 2022-06-20 00:23:49,427 >> loading file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1781] 2022-06-20 00:23:49,427 >> loading file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/347c648cda48ba9d519777e5e1e677a659862faeb5ad9e219ff0a95c62cfdea4.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1781] 2022-06-20 00:23:49,427 >> loading file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8bc519ac7a17e04e2e2de1908d5c2670888449f1489da619329762a3b21f6eb9.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|configuration_utils.py:659] 2022-06-20 00:23:49,573 >> loading configuration file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/020dab34d496eb711abcd1a2fcb98999e8e52a647a19a30d587ecf0dced64b4d.3c398df2e83e354046a333f011627deb67111e36b02711ab77c2f4004a414da9\n",
            "[INFO|configuration_utils.py:708] 2022-06-20 00:23:49,574 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlpaueb/bert-base-greek-uncased-v1\",\n",
            "  \"architectures\": [\n",
            "    \"BertForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 35000\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:659] 2022-06-20 00:23:49,768 >> loading configuration file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/020dab34d496eb711abcd1a2fcb98999e8e52a647a19a30d587ecf0dced64b4d.3c398df2e83e354046a333f011627deb67111e36b02711ab77c2f4004a414da9\n",
            "[INFO|configuration_utils.py:708] 2022-06-20 00:23:49,769 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlpaueb/bert-base-greek-uncased-v1\",\n",
            "  \"architectures\": [\n",
            "    \"BertForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 35000\n",
            "}\n",
            "\n",
            "[INFO|hub.py:592] 2022-06-20 00:23:49,987 >> https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdlwbo4_r\n",
            "Downloading: 100% 433M/433M [00:08<00:00, 56.6MB/s]\n",
            "[INFO|hub.py:596] 2022-06-20 00:23:58,073 >> storing https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/cdfc20f4044122272b65256247d0d166b5425bd7c8ebdb318654b3c8745f5d17.903cc72788b9d9d9aca17b92d3cce3100da85d9c12bbd577f417f08208ebe694\n",
            "[INFO|hub.py:604] 2022-06-20 00:23:58,073 >> creating metadata file for /root/.cache/huggingface/transformers/cdfc20f4044122272b65256247d0d166b5425bd7c8ebdb318654b3c8745f5d17.903cc72788b9d9d9aca17b92d3cce3100da85d9c12bbd577f417f08208ebe694\n",
            "[INFO|modeling_utils.py:2107] 2022-06-20 00:23:58,074 >> loading weights file https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/cdfc20f4044122272b65256247d0d166b5425bd7c8ebdb318654b3c8745f5d17.903cc72788b9d9d9aca17b92d3cce3100da85d9c12bbd577f417f08208ebe694\n",
            "[WARNING|modeling_utils.py:2474] 2022-06-20 00:23:59,911 >> Some weights of the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2486] 2022-06-20 00:23:59,911 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function main.<locals>.prepare_train_features at 0x7f3fe9b3ef80> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Running tokenizer on train dataset:   0% 0/214 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/Danastos___json/Danastos--squad_nq_el-6ce17c992b694ab3/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5/cache-1c80317fa3b1799d.arrow\n",
            "Running tokenizer on train dataset: 100% 214/214 [03:15<00:00,  1.09ba/s]\n",
            "INFO:datasets.fingerprint:Parameter 'function'=<function main.<locals>.prepare_validation_features at 0x7f3fe9ae3050> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Running tokenizer on validation dataset:   0% 0/14 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/Danastos___json/Danastos--squad_nq_el-6ce17c992b694ab3/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5/cache-bdd640fb06671ad1.arrow\n",
            "Running tokenizer on validation dataset: 100% 14/14 [01:38<00:00,  7.04s/ba]\n",
            "INFO:datasets.utils.file_utils:https://raw.githubusercontent.com/huggingface/datasets/2.3.2/metrics/squad_v2/squad_v2.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpq9viobkb\n",
            "Downloading builder script: 6.46kB [00:00, 2.38MB/s]       \n",
            "INFO:datasets.utils.file_utils:storing https://raw.githubusercontent.com/huggingface/datasets/2.3.2/metrics/squad_v2/squad_v2.py in cache at /root/.cache/huggingface/datasets/downloads/ecf600a07765d94dac2515a795fb1ac3a8999c92b621e7f137beb1ef302c9ca1.20ffda40aa962d94515737edbb5a7eda5c13e771416809a70e82ce2aee1820fd.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/ecf600a07765d94dac2515a795fb1ac3a8999c92b621e7f137beb1ef302c9ca1.20ffda40aa962d94515737edbb5a7eda5c13e771416809a70e82ce2aee1820fd.py\n",
            "INFO:datasets.utils.file_utils:https://raw.githubusercontent.com/huggingface/datasets/2.3.2/metrics/squad_v2/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp4a_o4vxk\n",
            "Downloading extra modules: 11.3kB [00:00, 4.50MB/s]       \n",
            "INFO:datasets.utils.file_utils:storing https://raw.githubusercontent.com/huggingface/datasets/2.3.2/metrics/squad_v2/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/db9e92238ae53d98bc56764e0801f3e8d49e20a54fb7725e1371a4847d1405ec.6a9a6adfaff0a516023cccce77ee4d9111e1f745161e3bb240d6eed53442d51d.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/db9e92238ae53d98bc56764e0801f3e8d49e20a54fb7725e1371a4847d1405ec.6a9a6adfaff0a516023cccce77ee4d9111e1f745161e3bb240d6eed53442d51d.py\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Cloning https://huggingface.co/Danastos/nq_squad_bert_el17 into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/Danastos/nq_squad_bert_el17 into local empty directory.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1517] 2022-06-20 00:29:06,793 >> ***** Running training *****\n",
            "[INFO|trainer.py:1518] 2022-06-20 00:29:06,794 >>   Num examples = 217257\n",
            "[INFO|trainer.py:1519] 2022-06-20 00:29:06,794 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1520] 2022-06-20 00:29:06,794 >>   Instantaneous batch size per device = 24\n",
            "[INFO|trainer.py:1521] 2022-06-20 00:29:06,794 >>   Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "[INFO|trainer.py:1522] 2022-06-20 00:29:06,794 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1523] 2022-06-20 00:29:06,794 >>   Total optimization steps = 27159\n",
            "{'loss': 2.3197, 'learning_rate': 2.9447696896056556e-05, 'epoch': 0.06}\n",
            "{'loss': 1.703, 'learning_rate': 2.8895393792113115e-05, 'epoch': 0.11}\n",
            "{'loss': 1.6232, 'learning_rate': 2.8343090688169667e-05, 'epoch': 0.17}\n",
            "{'loss': 1.5233, 'learning_rate': 2.7790787584226223e-05, 'epoch': 0.22}\n",
            "{'loss': 1.4893, 'learning_rate': 2.7238484480282782e-05, 'epoch': 0.28}\n",
            "{'loss': 1.4502, 'learning_rate': 2.6686181376339337e-05, 'epoch': 0.33}\n",
            "{'loss': 1.4233, 'learning_rate': 2.613387827239589e-05, 'epoch': 0.39}\n",
            "{'loss': 1.4043, 'learning_rate': 2.5581575168452448e-05, 'epoch': 0.44}\n",
            "{'loss': 1.3478, 'learning_rate': 2.5029272064509004e-05, 'epoch': 0.5}\n",
            "{'loss': 1.3371, 'learning_rate': 2.447696896056556e-05, 'epoch': 0.55}\n",
            "{'loss': 1.3137, 'learning_rate': 2.3924665856622115e-05, 'epoch': 0.61}\n",
            "{'loss': 1.294, 'learning_rate': 2.337236275267867e-05, 'epoch': 0.66}\n",
            "{'loss': 1.3092, 'learning_rate': 2.2820059648735226e-05, 'epoch': 0.72}\n",
            "{'loss': 1.2651, 'learning_rate': 2.226775654479178e-05, 'epoch': 0.77}\n",
            "{'loss': 1.2464, 'learning_rate': 2.171545344084834e-05, 'epoch': 0.83}\n",
            "{'loss': 1.259, 'learning_rate': 2.1163150336904892e-05, 'epoch': 0.88}\n",
            "{'loss': 1.2634, 'learning_rate': 2.0610847232961448e-05, 'epoch': 0.94}\n",
            "{'loss': 1.2198, 'learning_rate': 2.0058544129018007e-05, 'epoch': 0.99}\n",
            " 33% 9053/27159 [1:59:01<4:04:24,  1.23it/s]Metric: CompileTime\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 01m11s906ms985.993us\n",
            "  ValueRate: 010ms900.942us / second\n",
            "  Rate: 0.000837809 / second\n",
            "  Percentiles: 1%=014ms035.479us; 5%=014ms035.479us; 10%=014ms035.479us; 20%=102ms569.933us; 50%=21s820ms118.622us; 80%=23s940ms935.055us; 90%=26s869ms814.272us; 95%=26s869ms814.272us; 99%=26s869ms814.272us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 9109\n",
            "  Accumulator: 16s686ms815.462us\n",
            "  ValueRate: 002ms107.583us / second\n",
            "  Rate: 1.26023 / second\n",
            "  Percentiles: 1%=003.257us; 5%=003.619us; 10%=003.889us; 20%=004.340us; 50%=004.884us; 80%=005.402us; 90%=005.753us; 95%=006.107us; 99%=275.935us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 9090\n",
            "  Accumulator: 02h47m55s920ms309.393us\n",
            "  ValueRate: 887ms443.247us / second\n",
            "  Rate: 1.25775 / second\n",
            "  Percentiles: 1%=707ms664.223us; 5%=707ms267.179us; 10%=708ms596.623us; 20%=708ms926.651us; 50%=709ms531.628us; 80%=709ms176.069us; 90%=710ms741.373us; 95%=712ms291.884us; 99%=713ms393.652us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 18\n",
            "  Accumulator: 72.00B\n",
            "  ValueRate: 0.01B / second\n",
            "  Rate: 0.00270326 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=4.00B; 80%=4.00B; 90%=4.00B; 95%=4.00B; 99%=4.00B\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 2598.00\n",
            "  ValueRate: 0.36 / second\n",
            "  Rate: 0.000840118 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=1.00; 50%=798.00; 80%=798.00; 90%=798.00; 95%=798.00; 99%=798.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 201\n",
            "  Accumulator: 05s361ms712.325us\n",
            "  ValueRate: 01s219ms907.221us / second\n",
            "  Rate: 45.7029 / second\n",
            "  Percentiles: 1%=001ms427.585us; 5%=002ms630.932us; 10%=002ms721.007us; 20%=002ms855.713us; 50%=002ms205.607us; 80%=030ms507.452us; 90%=098ms938.582us; 95%=103ms321.125us; 99%=108ms691.758us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 20571\n",
            "  Accumulator: 2.34GB\n",
            "  ValueRate: 281.47KB / second\n",
            "  Rate: 2.8808 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=8.00B; 90%=892.50KB; 95%=892.50KB; 99%=892.50KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 492439\n",
            "  Accumulator: 06m08s434ms203.193us\n",
            "  ValueRate: 054ms256.150us / second\n",
            "  Rate: 72.8762 / second\n",
            "  Percentiles: 1%=401.255us; 5%=446.071us; 10%=470.520us; 20%=508.443us; 50%=643.901us; 80%=869.576us; 90%=001ms098.690us; 95%=001ms381.703us; 99%=002ms499.652us\n",
            "Metric: TensorToData\n",
            "  TotalSamples: 20571\n",
            "  Accumulator: 02h06m29s265ms287.250us\n",
            "  ValueRate: 01s070ms396.597us / second\n",
            "  Rate: 2.8808 / second\n",
            "  Percentiles: 1%=002ms702.411us; 5%=002ms910.180us; 10%=002ms996.397us; 20%=002ms120.687us; 50%=633ms187.487us; 80%=699ms635.979us; 90%=701ms516.169us; 95%=702ms683.737us; 99%=703ms568.154us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 9090\n",
            "  Accumulator: 102145496.00\n",
            "  ValueRate: 14128.56 / second\n",
            "  Rate: 1.25711 / second\n",
            "  Percentiles: 1%=11283.00; 5%=11283.00; 10%=11283.00; 20%=11283.00; 50%=11283.00; 80%=11283.00; 90%=11283.00; 95%=11283.00; 99%=11283.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 18\n",
            "  Accumulator: 136ms939.324us\n",
            "  ValueRate: 020.416us / second\n",
            "  Rate: 0.00270326 / second\n",
            "  Percentiles: 1%=001ms302.696us; 5%=001ms302.696us; 10%=002ms525.859us; 20%=002ms776.547us; 50%=009ms650.844us; 80%=014ms180.288us; 90%=015ms592.162us; 95%=016ms838.370us; 99%=016ms838.370us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 20571\n",
            "  Accumulator: 02h06m29s876ms066.192us\n",
            "  ValueRate: 01s070ms344.166us / second\n",
            "  Rate: 2.8808 / second\n",
            "  Percentiles: 1%=002ms693.236us; 5%=002ms903.116us; 10%=002ms988.130us; 20%=002ms113.118us; 50%=633ms174.857us; 80%=699ms625.641us; 90%=700ms426.750us; 95%=702ms595.385us; 99%=702ms473.988us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 20571\n",
            "  Accumulator: 11s002ms620.450us\n",
            "  ValueRate: 001ms497.504us / second\n",
            "  Rate: 2.8808 / second\n",
            "  Percentiles: 1%=066.057us; 5%=075.030us; 10%=080.468us; 20%=086.265us; 50%=143.309us; 80%=176.665us; 90%=002ms317.724us; 95%=003ms279.806us; 99%=005ms903.288us\n",
            "Counter: CachedCompile\n",
            "  Value: 9084\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 6\n",
            "Counter: CreateDataHandles\n",
            "  Value: 7288104\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 44622674\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 7286373\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 44621869\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 9053\n",
            "Counter: MarkStep\n",
            "  Value: 9073\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 7287171\n",
            "Counter: UncachedCompile\n",
            "  Value: 6\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 59\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtSessionCount\n",
            "  Value: 12\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 1280\n",
            "Counter: xla::_copy_from\n",
            "  Value: 13651945\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 18106\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 18106\n",
            "Counter: xla::_s_where\n",
            "  Value: 9053\n",
            "Counter: xla::_softmax\n",
            "  Value: 108636\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 108636\n",
            "Counter: xla::_unsafe_view\n",
            "  Value: 878141\n",
            "Counter: xla::add\n",
            "  Value: 6871028\n",
            "Counter: xla::addcdiv_\n",
            "  Value: 1801547\n",
            "Counter: xla::addcmul\n",
            "  Value: 2027872\n",
            "Counter: xla::bernoulli_\n",
            "  Value: 334961\n",
            "Counter: xla::bmm\n",
            "  Value: 651816\n",
            "Counter: xla::cat\n",
            "  Value: 9053\n",
            "Counter: xla::clamp\n",
            "  Value: 18106\n",
            "Counter: xla::div\n",
            "  Value: 579392\n",
            "Counter: xla::embedding\n",
            "  Value: 27159\n",
            "Counter: xla::embedding_dense_backward\n",
            "  Value: 27159\n",
            "Counter: xla::empty\n",
            "  Value: 371773\n",
            "Counter: xla::expand\n",
            "  Value: 434544\n",
            "Counter: xla::fill_\n",
            "  Value: 9053\n",
            "Counter: xla::gelu\n",
            "  Value: 108636\n",
            "Counter: xla::gelu_backward\n",
            "  Value: 108636\n",
            "Counter: xla::index_select\n",
            "  Value: 27159\n",
            "Counter: xla::lt\n",
            "  Value: 9053\n",
            "Counter: xla::mm\n",
            "  Value: 1982607\n",
            "Counter: xla::mul\n",
            "  Value: 6988916\n",
            "Counter: xla::native_batch_norm\n",
            "  Value: 226325\n",
            "Counter: xla::native_batch_norm_backward\n",
            "  Value: 226325\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 18106\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 18106\n",
            "Counter: xla::norm\n",
            "  Value: 1810600\n",
            "Counter: xla::permute\n",
            "  Value: 869088\n",
            "Counter: xla::rsub\n",
            "  Value: 9053\n",
            "Counter: xla::slice\n",
            "  Value: 36212\n",
            "Counter: xla::split\n",
            "  Value: 9053\n",
            "Counter: xla::sqrt\n",
            "  Value: 1801547\n",
            "Counter: xla::squeeze\n",
            "  Value: 18106\n",
            "Counter: xla::stack\n",
            "  Value: 9053\n",
            "Counter: xla::sub\n",
            "  Value: 18\n",
            "Counter: xla::sum\n",
            "  Value: 1122572\n",
            "Counter: xla::t\n",
            "  Value: 2643476\n",
            "Counter: xla::transpose\n",
            "  Value: 651816\n",
            "Counter: xla::unsqueeze\n",
            "  Value: 36212\n",
            "Counter: xla::view\n",
            "  Value: 7342001\n",
            "Counter: xla::zero_\n",
            "  Value: 1801945\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 63572\n",
            "  Accumulator: 02m57s933ms081.711us\n",
            "  Mean: 002ms809.592us\n",
            "  StdDev: 001ms011.238us\n",
            "  Rate: 8.74254 / second\n",
            "  Percentiles: 25%=620.316us; 50%=002ms065.789us; 80%=003ms756.489us; 90%=003ms052.915us; 95%=003ms222.198us; 99%=004ms679.181us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 01m10s344ms291.316us\n",
            "  Mean: 12s724ms048.553us\n",
            "  StdDev: 11s472ms365.705us\n",
            "  Rate: 0.0008378 / second\n",
            "  Percentiles: 25%=014ms947.617us; 50%=21s654ms706.673us; 80%=23s857ms174.153us; 90%=26s774ms372.809us; 95%=26s774ms372.809us; 99%=26s774ms372.809us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 9090\n",
            "  Accumulator: 02h46m22s785ms737.214us\n",
            "  Mean: 702ms910.967us\n",
            "  StdDev: 046ms855.186us\n",
            "  Rate: 1.25775 / second\n",
            "  Percentiles: 25%=705ms727.106us; 50%=705ms108.190us; 80%=706ms587.246us; 90%=706ms823.889us; 95%=706ms018.249us; 99%=706ms365.339us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 18\n",
            "  Accumulator: 011ms067.884us\n",
            "  Mean: 614.882us\n",
            "  StdDev: 149.995us\n",
            "  Rate: 0.00270322 / second\n",
            "  Percentiles: 25%=514.181us; 50%=597.537us; 80%=734.857us; 90%=864.272us; 95%=935.864us; 99%=935.864us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 492440\n",
            "  Accumulator: 18s007ms347.700us\n",
            "  Mean: 046.815us\n",
            "  StdDev: 180.734us\n",
            "  Rate: 28.9253 / second\n",
            "  Percentiles: 25%=003.584us; 50%=005.583us; 80%=020.887us; 90%=057.931us; 95%=155.304us; 99%=001ms065.446us\n",
            "\n",
            "{'loss': 1.0049, 'learning_rate': 1.9506241025074562e-05, 'epoch': 1.05}\n",
            "{'loss': 0.9879, 'learning_rate': 1.8953937921131114e-05, 'epoch': 1.1}\n",
            " 37% 10000/27159 [2:11:48<3:42:17,  1.29it/s][INFO|trainer.py:2474] 2022-06-20 02:40:55,442 >> Saving model checkpoint to /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-10000\n",
            "[INFO|configuration_utils.py:446] 2022-06-20 02:40:55,464 >> Configuration saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-10000/config.json\n",
            "[INFO|modeling_utils.py:1660] 2022-06-20 02:41:01,600 >> Model weights saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-10000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-06-20 02:41:01,610 >> tokenizer config file saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-10000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-06-20 02:41:01,615 >> Special tokens file saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-10000/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-06-20 02:41:23,217 >> tokenizer config file saved in /content/drive/MyDrive/nq_squad_bert_el17/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-06-20 02:41:23,245 >> Special tokens file saved in /content/drive/MyDrive/nq_squad_bert_el17/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "{'loss': 0.9773, 'learning_rate': 1.8401634817187673e-05, 'epoch': 1.16}\n",
            "{'loss': 0.9861, 'learning_rate': 1.784933171324423e-05, 'epoch': 1.22}\n",
            "{'loss': 0.9843, 'learning_rate': 1.7297028609300784e-05, 'epoch': 1.27}\n",
            "{'loss': 0.9949, 'learning_rate': 1.674472550535734e-05, 'epoch': 1.33}\n",
            "{'loss': 0.9949, 'learning_rate': 1.6192422401413895e-05, 'epoch': 1.38}\n",
            "{'loss': 0.9876, 'learning_rate': 1.564011929747045e-05, 'epoch': 1.44}\n",
            "{'loss': 0.9709, 'learning_rate': 1.5087816193527008e-05, 'epoch': 1.49}\n",
            "{'loss': 0.9915, 'learning_rate': 1.4535513089583564e-05, 'epoch': 1.55}\n",
            "{'loss': 0.9869, 'learning_rate': 1.3983209985640121e-05, 'epoch': 1.6}\n",
            "{'loss': 0.9745, 'learning_rate': 1.3430906881696675e-05, 'epoch': 1.66}\n",
            "{'loss': 0.9764, 'learning_rate': 1.2878603777753232e-05, 'epoch': 1.71}\n",
            "{'loss': 0.9589, 'learning_rate': 1.2326300673809787e-05, 'epoch': 1.77}\n",
            "{'loss': 0.9683, 'learning_rate': 1.1773997569866343e-05, 'epoch': 1.82}\n",
            "{'loss': 0.9511, 'learning_rate': 1.1221694465922899e-05, 'epoch': 1.88}\n",
            "{'loss': 0.9454, 'learning_rate': 1.0669391361979454e-05, 'epoch': 1.93}\n",
            "{'loss': 0.9504, 'learning_rate': 1.011708825803601e-05, 'epoch': 1.99}\n",
            " 67% 18106/27159 [3:57:54<1:55:58,  1.30it/s]Metric: CompileTime\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 01m11s906ms985.993us\n",
            "  ValueRate: 010ms900.942us / second\n",
            "  Rate: 0.000837809 / second\n",
            "  Percentiles: 1%=014ms035.479us; 5%=014ms035.479us; 10%=014ms035.479us; 20%=102ms569.933us; 50%=21s820ms118.622us; 80%=23s940ms935.055us; 90%=26s869ms814.272us; 95%=26s869ms814.272us; 99%=26s869ms814.272us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 18222\n",
            "  Accumulator: 29s783ms629.506us\n",
            "  ValueRate: 002ms102.369us / second\n",
            "  Rate: 1.29374 / second\n",
            "  Percentiles: 1%=003.089us; 5%=003.464us; 10%=003.764us; 20%=004.206us; 50%=004.863us; 80%=005.355us; 90%=005.695us; 95%=006.088us; 99%=547.200us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 18179\n",
            "  Accumulator: 04h34m52s690ms719.578us\n",
            "  ValueRate: 911ms983.995us / second\n",
            "  Rate: 1.29112 / second\n",
            "  Percentiles: 1%=707ms626.528us; 5%=707ms199.838us; 10%=708ms571.132us; 20%=708ms042.940us; 50%=709ms664.747us; 80%=709ms229.668us; 90%=710ms687.509us; 95%=712ms040.539us; 99%=713ms123.828us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 38\n",
            "  Accumulator: 1.26GB\n",
            "  ValueRate: 95.73KB / second\n",
            "  Rate: 0.00276351 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=4.00B; 80%=4.00B; 90%=4.00B; 95%=428.52MB; 99%=857.03MB\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 2598.00\n",
            "  ValueRate: 0.36 / second\n",
            "  Rate: 0.000840118 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=1.00; 50%=798.00; 80%=798.00; 90%=798.00; 95%=798.00; 99%=798.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 201\n",
            "  Accumulator: 05s361ms712.325us\n",
            "  ValueRate: 01s219ms907.221us / second\n",
            "  Rate: 45.7029 / second\n",
            "  Percentiles: 1%=001ms427.585us; 5%=002ms630.932us; 10%=002ms721.007us; 20%=002ms855.713us; 50%=002ms205.607us; 80%=030ms507.452us; 90%=098ms938.582us; 95%=103ms321.125us; 99%=108ms691.758us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 40941\n",
            "  Accumulator: 4.27GB\n",
            "  ValueRate: 283.50KB / second\n",
            "  Rate: 2.90159 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=8.00B; 90%=892.50KB; 95%=892.50KB; 99%=892.50KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 950470\n",
            "  Accumulator: 12m59s798ms108.183us\n",
            "  ValueRate: 071ms872.711us / second\n",
            "  Rate: 97.7576 / second\n",
            "  Percentiles: 1%=400.903us; 5%=440.230us; 10%=461.148us; 20%=492.806us; 50%=602.921us; 80%=778.961us; 90%=001ms011.077us; 95%=001ms388.803us; 99%=003ms857.556us\n",
            "Metric: TensorToData\n",
            "  TotalSamples: 40941\n",
            "  Accumulator: 04h13m31s500ms226.870us\n",
            "  ValueRate: 01s071ms547.950us / second\n",
            "  Rate: 2.89621 / second\n",
            "  Percentiles: 1%=002ms702.313us; 5%=002ms924.071us; 10%=002ms007.362us; 20%=002ms157.558us; 50%=633ms274.954us; 80%=698ms483.604us; 90%=700ms457.223us; 95%=702ms722.331us; 99%=703ms126.926us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 18179\n",
            "  Accumulator: 204290603.00\n",
            "  ValueRate: 14502.06 / second\n",
            "  Rate: 1.29034 / second\n",
            "  Percentiles: 1%=11283.00; 5%=11283.00; 10%=11283.00; 20%=11283.00; 50%=11283.00; 80%=11283.00; 90%=11283.00; 95%=11283.00; 99%=11283.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 38\n",
            "  Accumulator: 10s719ms082.429us\n",
            "  ValueRate: 706.811us / second\n",
            "  Rate: 0.00276351 / second\n",
            "  Percentiles: 1%=001ms266.768us; 5%=001ms302.696us; 10%=002ms525.859us; 20%=002ms634.755us; 50%=002ms939.425us; 80%=014ms949.953us; 90%=015ms743.407us; 95%=03s199ms747.570us; 99%=06s340ms720.318us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 40941\n",
            "  Accumulator: 04h12m30s742ms071.593us\n",
            "  ValueRate: 01s070ms495.171us / second\n",
            "  Rate: 2.89621 / second\n",
            "  Percentiles: 1%=002ms697.043us; 5%=002ms916.194us; 10%=002ms999.635us; 20%=002ms150.021us; 50%=633ms261.696us; 80%=698ms473.371us; 90%=700ms411.093us; 95%=702ms635.775us; 99%=703ms034.928us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 40941\n",
            "  Accumulator: 22s680ms311.071us\n",
            "  ValueRate: 002ms605.197us / second\n",
            "  Rate: 2.90159 / second\n",
            "  Percentiles: 1%=062.764us; 5%=070.697us; 10%=077.318us; 20%=084.704us; 50%=135.777us; 80%=176.031us; 90%=003ms610.783us; 95%=003ms414.581us; 99%=009ms503.906us\n",
            "Counter: CachedCompile\n",
            "  Value: 18173\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 6\n",
            "Counter: CreateDataHandles\n",
            "  Value: 14575805\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 89244947\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 14574872\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 89244142\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 18106\n",
            "Counter: MarkStep\n",
            "  Value: 18146\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 14574872\n",
            "Counter: UncachedCompile\n",
            "  Value: 6\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 64\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 1662\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtSessionCount\n",
            "  Value: 12\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 1280\n",
            "Counter: xla::_copy_from\n",
            "  Value: 27303887\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 36212\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 36212\n",
            "Counter: xla::_s_where\n",
            "  Value: 18106\n",
            "Counter: xla::_softmax\n",
            "  Value: 217272\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 217272\n",
            "Counter: xla::_unsafe_view\n",
            "  Value: 1756282\n",
            "Counter: xla::add\n",
            "  Value: 13742255\n",
            "Counter: xla::addcdiv_\n",
            "  Value: 3603094\n",
            "Counter: xla::addcmul\n",
            "  Value: 4055744\n",
            "Counter: xla::bernoulli_\n",
            "  Value: 669922\n",
            "Counter: xla::bmm\n",
            "  Value: 1303632\n",
            "Counter: xla::cat\n",
            "  Value: 18106\n",
            "Counter: xla::clamp\n",
            "  Value: 36212\n",
            "Counter: xla::div\n",
            "  Value: 1158784\n",
            "Counter: xla::embedding\n",
            "  Value: 54318\n",
            "Counter: xla::embedding_dense_backward\n",
            "  Value: 54318\n",
            "Counter: xla::empty\n",
            "  Value: 742946\n",
            "Counter: xla::expand\n",
            "  Value: 869088\n",
            "Counter: xla::fill_\n",
            "  Value: 18106\n",
            "Counter: xla::gelu\n",
            "  Value: 217272\n",
            "Counter: xla::gelu_backward\n",
            "  Value: 217272\n",
            "Counter: xla::index_select\n",
            "  Value: 54318\n",
            "Counter: xla::lt\n",
            "  Value: 18106\n",
            "Counter: xla::mm\n",
            "  Value: 3965214\n",
            "Counter: xla::mul\n",
            "  Value: 13977832\n",
            "Counter: xla::native_batch_norm\n",
            "  Value: 452650\n",
            "Counter: xla::native_batch_norm_backward\n",
            "  Value: 452650\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 36212\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 36212\n",
            "Counter: xla::norm\n",
            "  Value: 3621200\n",
            "Counter: xla::permute\n",
            "  Value: 1738176\n",
            "Counter: xla::rsub\n",
            "  Value: 18106\n",
            "Counter: xla::slice\n",
            "  Value: 72424\n",
            "Counter: xla::split\n",
            "  Value: 18106\n",
            "Counter: xla::sqrt\n",
            "  Value: 3603094\n",
            "Counter: xla::squeeze\n",
            "  Value: 36212\n",
            "Counter: xla::stack\n",
            "  Value: 18106\n",
            "Counter: xla::sub\n",
            "  Value: 36\n",
            "Counter: xla::sum\n",
            "  Value: 2245144\n",
            "Counter: xla::t\n",
            "  Value: 5286952\n",
            "Counter: xla::transpose\n",
            "  Value: 1303632\n",
            "Counter: xla::unsqueeze\n",
            "  Value: 72424\n",
            "Counter: xla::view\n",
            "  Value: 14684002\n",
            "Counter: xla::zero_\n",
            "  Value: 3603492\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 126943\n",
            "  Accumulator: 04m53s858ms070.325us\n",
            "  Mean: 002ms829.554us\n",
            "  StdDev: 983.721us\n",
            "  Rate: 8.80299 / second\n",
            "  Percentiles: 25%=693.133us; 50%=002ms115.037us; 80%=003ms768.805us; 90%=003ms980.638us; 95%=003ms127.208us; 99%=004ms537.240us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 01m10s344ms291.316us\n",
            "  Mean: 12s724ms048.553us\n",
            "  StdDev: 11s472ms365.705us\n",
            "  Rate: 0.0008378 / second\n",
            "  Percentiles: 25%=014ms947.617us; 50%=21s654ms706.673us; 80%=23s857ms174.153us; 90%=26s774ms372.809us; 95%=26s774ms372.809us; 99%=26s774ms372.809us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 18179\n",
            "  Accumulator: 04h33m45s655ms933.971us\n",
            "  Mean: 702ms951.851us\n",
            "  StdDev: 046ms346.632us\n",
            "  Rate: 1.29112 / second\n",
            "  Percentiles: 25%=705ms802.678us; 50%=705ms240.757us; 80%=706ms681.827us; 90%=706ms918.702us; 95%=706ms111.773us; 99%=706ms426.543us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 634\n",
            "  Accumulator: 01m05s206ms760.154us\n",
            "  Mean: 103ms848.202us\n",
            "  StdDev: 079ms051.975us\n",
            "  Rate: 0.0461067 / second\n",
            "  Percentiles: 25%=041ms557.964us; 50%=087ms117.334us; 80%=176ms419.073us; 90%=203ms098.895us; 95%=229ms124.095us; 99%=345ms968.201us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 950470\n",
            "  Accumulator: 41s561ms493.152us\n",
            "  Mean: 032.879us\n",
            "  StdDev: 147.928us\n",
            "  Rate: 97.7574 / second\n",
            "  Percentiles: 25%=002.789us; 50%=003.972us; 80%=008.141us; 90%=029.906us; 95%=096.287us; 99%=935.136us\n",
            "\n",
            "{'loss': 0.7908, 'learning_rate': 9.564785154092567e-06, 'epoch': 2.04}\n",
            "{'loss': 0.7257, 'learning_rate': 9.012482050149122e-06, 'epoch': 2.1}\n",
            "{'loss': 0.7165, 'learning_rate': 8.460178946205678e-06, 'epoch': 2.15}\n",
            "{'loss': 0.7269, 'learning_rate': 7.907875842262235e-06, 'epoch': 2.21}\n",
            " 74% 20000/27159 [4:22:24<1:30:20,  1.32it/s][INFO|trainer.py:2474] 2022-06-20 04:51:31,847 >> Saving model checkpoint to /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-20000\n",
            "[INFO|configuration_utils.py:446] 2022-06-20 04:51:31,869 >> Configuration saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-20000/config.json\n",
            "[INFO|modeling_utils.py:1660] 2022-06-20 04:51:39,909 >> Model weights saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-20000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-06-20 04:51:39,915 >> tokenizer config file saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-20000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-06-20 04:51:39,979 >> Special tokens file saved in /content/drive/MyDrive/nq_squad_bert_el17/checkpoint-20000/special_tokens_map.json\n",
            "{'loss': 0.7267, 'learning_rate': 7.35557273831879e-06, 'epoch': 2.26}\n",
            "{'loss': 0.7132, 'learning_rate': 6.803269634375345e-06, 'epoch': 2.32}\n",
            "{'loss': 0.7155, 'learning_rate': 6.250966530431901e-06, 'epoch': 2.37}\n",
            "{'loss': 0.721, 'learning_rate': 5.698663426488457e-06, 'epoch': 2.43}\n",
            "{'loss': 0.7134, 'learning_rate': 5.1463603225450134e-06, 'epoch': 2.49}\n",
            "{'loss': 0.6966, 'learning_rate': 4.594057218601569e-06, 'epoch': 2.54}\n",
            "{'loss': 0.7128, 'learning_rate': 4.0417541146581245e-06, 'epoch': 2.6}\n",
            "{'loss': 0.7371, 'learning_rate': 3.4894510107146804e-06, 'epoch': 2.65}\n",
            "{'loss': 0.7237, 'learning_rate': 2.9371479067712364e-06, 'epoch': 2.71}\n",
            "{'loss': 0.7324, 'learning_rate': 2.384844802827792e-06, 'epoch': 2.76}\n",
            "{'loss': 0.7073, 'learning_rate': 1.8325416988843476e-06, 'epoch': 2.82}\n",
            "{'loss': 0.6995, 'learning_rate': 1.2802385949409037e-06, 'epoch': 2.87}\n",
            "{'loss': 0.7121, 'learning_rate': 7.279354909974594e-07, 'epoch': 2.93}\n",
            "{'loss': 0.6906, 'learning_rate': 1.7563238705401526e-07, 'epoch': 2.98}\n",
            "100% 27159/27159 [5:55:32<00:00,  1.31it/s]Metric: CompileTime\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 01m11s906ms985.993us\n",
            "  ValueRate: 010ms900.942us / second\n",
            "  Rate: 0.000837809 / second\n",
            "  Percentiles: 1%=014ms035.479us; 5%=014ms035.479us; 10%=014ms035.479us; 20%=102ms569.933us; 50%=21s820ms118.622us; 80%=23s940ms935.055us; 90%=26s869ms814.272us; 95%=26s869ms814.272us; 99%=26s869ms814.272us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 27333\n",
            "  Accumulator: 42s644ms567.953us\n",
            "  ValueRate: 002ms802.775us / second\n",
            "  Rate: 1.29957 / second\n",
            "  Percentiles: 1%=002.912us; 5%=003.178us; 10%=003.415us; 20%=003.812us; 50%=004.567us; 80%=005.088us; 90%=005.374us; 95%=005.826us; 99%=016.475us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 27267\n",
            "  Accumulator: 05h21m48s269ms437.464us\n",
            "  ValueRate: 916ms804.766us / second\n",
            "  Rate: 1.29702 / second\n",
            "  Percentiles: 1%=707ms760.537us; 5%=707ms390.711us; 10%=708ms694.463us; 20%=708ms049.461us; 50%=709ms607.283us; 80%=709ms242.514us; 90%=710ms787.510us; 95%=712ms236.071us; 99%=713ms466.925us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 58\n",
            "  Accumulator: 2.51GB\n",
            "  ValueRate: 126.77KB / second\n",
            "  Rate: 0.00279269 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=4.00B; 80%=4.00B; 90%=4.00B; 95%=428.52MB; 99%=857.03MB\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 2598.00\n",
            "  ValueRate: 0.36 / second\n",
            "  Rate: 0.000840118 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=1.00; 50%=798.00; 80%=798.00; 90%=798.00; 95%=798.00; 99%=798.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 201\n",
            "  Accumulator: 05s361ms712.325us\n",
            "  ValueRate: 01s219ms907.221us / second\n",
            "  Rate: 45.7029 / second\n",
            "  Percentiles: 1%=001ms427.585us; 5%=002ms630.932us; 10%=002ms721.007us; 20%=002ms855.713us; 50%=002ms205.607us; 80%=030ms507.452us; 90%=098ms938.582us; 95%=103ms321.125us; 99%=108ms691.758us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 61311\n",
            "  Accumulator: 6.20GB\n",
            "  ValueRate: 284.78KB / second\n",
            "  Rate: 2.91471 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=8.00B; 90%=892.50KB; 95%=892.50KB; 99%=892.50KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 1333094\n",
            "  Accumulator: 17m01s838ms929.064us\n",
            "  ValueRate: 071ms698.293us / second\n",
            "  Rate: 93.7841 / second\n",
            "  Percentiles: 1%=397.820us; 5%=431.890us; 10%=456.583us; 20%=493.664us; 50%=617.394us; 80%=845.724us; 90%=001ms156.314us; 95%=001ms480.154us; 99%=003ms015.975us\n",
            "Metric: TensorToData\n",
            "  TotalSamples: 61311\n",
            "  Accumulator: 06h19m30s329ms650.309us\n",
            "  ValueRate: 01s076ms246.841us / second\n",
            "  Rate: 2.9094 / second\n",
            "  Percentiles: 1%=002ms659.724us; 5%=002ms881.922us; 10%=002ms977.923us; 20%=002ms113.720us; 50%=634ms795.793us; 80%=684ms397.944us; 90%=701ms559.517us; 95%=702ms780.682us; 99%=703ms785.809us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 27267\n",
            "  Accumulator: 306424427.00\n",
            "  ValueRate: 14577.18 / second\n",
            "  Rate: 1.29702 / second\n",
            "  Percentiles: 1%=11283.00; 5%=11283.00; 10%=11283.00; 20%=11283.00; 50%=11283.00; 80%=11283.00; 90%=11283.00; 95%=11283.00; 99%=11283.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 58\n",
            "  Accumulator: 20s633ms606.453us\n",
            "  ValueRate: 945.307us / second\n",
            "  Rate: 0.00279269 / second\n",
            "  Percentiles: 1%=001ms266.768us; 5%=001ms323.465us; 10%=001ms473.962us; 20%=002ms589.790us; 50%=002ms908.467us; 80%=013ms874.879us; 90%=015ms743.407us; 95%=04s943ms302.261us; 99%=06s340ms720.318us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 61311\n",
            "  Accumulator: 06h18m29s212ms358.478us\n",
            "  ValueRate: 01s076ms196.381us / second\n",
            "  Rate: 2.9094 / second\n",
            "  Percentiles: 1%=002ms648.064us; 5%=002ms876.539us; 10%=002ms971.783us; 20%=002ms107.554us; 50%=634ms785.107us; 80%=684ms373.377us; 90%=700ms471.083us; 95%=702ms683.874us; 99%=703ms711.929us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 61311\n",
            "  Accumulator: 32s291ms286.148us\n",
            "  ValueRate: 002ms521.195us / second\n",
            "  Rate: 2.91471 / second\n",
            "  Percentiles: 1%=058.049us; 5%=066.539us; 10%=074.060us; 20%=081.228us; 50%=119.579us; 80%=170.729us; 90%=002ms022.115us; 95%=003ms299.244us; 99%=009ms540.861us\n",
            "Counter: CachedCompile\n",
            "  Value: 27261\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 6\n",
            "Counter: CreateDataHandles\n",
            "  Value: 21862708\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 133867220\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 21861775\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 133866415\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 27159\n",
            "Counter: MarkStep\n",
            "  Value: 27217\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 21861775\n",
            "Counter: UncachedCompile\n",
            "  Value: 6\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 64\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 2044\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 1280\n",
            "Counter: XrtSessionCount\n",
            "  Value: 12\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 1280\n",
            "Counter: xla::_copy_from\n",
            "  Value: 40955829\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 54318\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 54318\n",
            "Counter: xla::_s_where\n",
            "  Value: 27159\n",
            "Counter: xla::_softmax\n",
            "  Value: 325908\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 325908\n",
            "Counter: xla::_unsafe_view\n",
            "  Value: 2634423\n",
            "Counter: xla::add\n",
            "  Value: 20613482\n",
            "Counter: xla::addcdiv_\n",
            "  Value: 5404641\n",
            "Counter: xla::addcmul\n",
            "  Value: 6083616\n",
            "Counter: xla::bernoulli_\n",
            "  Value: 1004883\n",
            "Counter: xla::bmm\n",
            "  Value: 1955448\n",
            "Counter: xla::cat\n",
            "  Value: 27159\n",
            "Counter: xla::clamp\n",
            "  Value: 54318\n",
            "Counter: xla::div\n",
            "  Value: 1738176\n",
            "Counter: xla::embedding\n",
            "  Value: 81477\n",
            "Counter: xla::embedding_dense_backward\n",
            "  Value: 81477\n",
            "Counter: xla::empty\n",
            "  Value: 1114119\n",
            "Counter: xla::expand\n",
            "  Value: 1303632\n",
            "Counter: xla::fill_\n",
            "  Value: 27159\n",
            "Counter: xla::gelu\n",
            "  Value: 325908\n",
            "Counter: xla::gelu_backward\n",
            "  Value: 325908\n",
            "Counter: xla::index_select\n",
            "  Value: 81477\n",
            "Counter: xla::lt\n",
            "  Value: 27159\n",
            "Counter: xla::mm\n",
            "  Value: 5947821\n",
            "Counter: xla::mul\n",
            "  Value: 20966748\n",
            "Counter: xla::native_batch_norm\n",
            "  Value: 678975\n",
            "Counter: xla::native_batch_norm_backward\n",
            "  Value: 678975\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 54318\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 54318\n",
            "Counter: xla::norm\n",
            "  Value: 5431800\n",
            "Counter: xla::permute\n",
            "  Value: 2607264\n",
            "Counter: xla::rsub\n",
            "  Value: 27159\n",
            "Counter: xla::slice\n",
            "  Value: 108636\n",
            "Counter: xla::split\n",
            "  Value: 27159\n",
            "Counter: xla::sqrt\n",
            "  Value: 5404641\n",
            "Counter: xla::squeeze\n",
            "  Value: 54318\n",
            "Counter: xla::stack\n",
            "  Value: 27159\n",
            "Counter: xla::sub\n",
            "  Value: 54\n",
            "Counter: xla::sum\n",
            "  Value: 3367716\n",
            "Counter: xla::t\n",
            "  Value: 7930428\n",
            "Counter: xla::transpose\n",
            "  Value: 1955448\n",
            "Counter: xla::unsqueeze\n",
            "  Value: 108636\n",
            "Counter: xla::view\n",
            "  Value: 22026003\n",
            "Counter: xla::zero_\n",
            "  Value: 5405039\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 190314\n",
            "  Accumulator: 06m49s972ms612.649us\n",
            "  Mean: 002ms855.336us\n",
            "  StdDev: 991.942us\n",
            "  Rate: 8.90597 / second\n",
            "  Percentiles: 25%=701.797us; 50%=002ms125.053us; 80%=003ms787.879us; 90%=003ms051.426us; 95%=003ms212.376us; 99%=004ms568.090us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 01m10s344ms291.316us\n",
            "  Mean: 12s724ms048.553us\n",
            "  StdDev: 11s472ms365.705us\n",
            "  Rate: 0.0008378 / second\n",
            "  Percentiles: 25%=014ms947.617us; 50%=21s654ms706.673us; 80%=23s857ms174.153us; 90%=26s774ms372.809us; 95%=26s774ms372.809us; 99%=26s774ms372.809us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 27267\n",
            "  Accumulator: 05h19m08s958ms838.911us\n",
            "  Mean: 702ms456.137us\n",
            "  StdDev: 044ms894.701us\n",
            "  Rate: 1.29702 / second\n",
            "  Percentiles: 25%=705ms861.172us; 50%=705ms226.321us; 80%=706ms682.481us; 90%=706ms918.992us; 95%=706ms142.687us; 99%=706ms439.378us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 1250\n",
            "  Accumulator: 02m01s369ms292.743us\n",
            "  Mean: 088ms409.876us\n",
            "  StdDev: 056ms539.060us\n",
            "  Rate: 0.0770174 / second\n",
            "  Percentiles: 25%=054ms931.301us; 50%=081ms772.450us; 80%=139ms574.368us; 90%=170ms601.508us; 95%=180ms568.270us; 99%=203ms896.677us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 1333094\n",
            "  Accumulator: 01m02s037ms280.570us\n",
            "  Mean: 048.288us\n",
            "  StdDev: 211.016us\n",
            "  Rate: 93.8034 / second\n",
            "  Percentiles: 25%=002.972us; 50%=004.273us; 80%=009.728us; 90%=051.519us; 95%=158.473us; 99%=001ms291.385us\n",
            "\n",
            "[INFO|trainer.py:1762] 2022-06-20 06:24:39,520 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 21339.2001, 'train_samples_per_second': 30.543, 'train_steps_per_second': 1.273, 'train_loss': 1.0412359723304234, 'epoch': 3.0}\n",
            "100% 27159/27159 [5:55:39<00:00,  1.27it/s]\n",
            "[INFO|trainer.py:2474] 2022-06-20 06:24:46,011 >> Saving model checkpoint to /content/drive/MyDrive/nq_squad_bert_el17\n",
            "[INFO|configuration_utils.py:446] 2022-06-20 06:24:46,028 >> Configuration saved in /content/drive/MyDrive/nq_squad_bert_el17/config.json\n",
            "[INFO|modeling_utils.py:1660] 2022-06-20 06:25:12,949 >> Model weights saved in /content/drive/MyDrive/nq_squad_bert_el17/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-06-20 06:25:12,955 >> tokenizer config file saved in /content/drive/MyDrive/nq_squad_bert_el17/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-06-20 06:25:12,960 >> Special tokens file saved in /content/drive/MyDrive/nq_squad_bert_el17/special_tokens_map.json\n",
            "[INFO|trainer.py:2474] 2022-06-20 06:25:13,076 >> Saving model checkpoint to /content/drive/MyDrive/nq_squad_bert_el17\n",
            "[INFO|configuration_utils.py:446] 2022-06-20 06:25:13,089 >> Configuration saved in /content/drive/MyDrive/nq_squad_bert_el17/config.json\n",
            "[INFO|modeling_utils.py:1660] 2022-06-20 06:25:17,732 >> Model weights saved in /content/drive/MyDrive/nq_squad_bert_el17/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-06-20 06:25:17,737 >> tokenizer config file saved in /content/drive/MyDrive/nq_squad_bert_el17/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-06-20 06:25:17,742 >> Special tokens file saved in /content/drive/MyDrive/nq_squad_bert_el17/special_tokens_map.json\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n",
            "WARNING:huggingface_hub.repository:The progress bars may be unreliable.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!python run_qa.py \\\n",
        "  --model_name_or_path  nlpaueb/bert-base-greek-uncased-v1  \\\n",
        "  --dataset_name Danastos/squad_el_custom \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --per_device_train_batch_size 24 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --max_seq_length 396 \\\n",
        "  --doc_stride 132 \\\n",
        "  --push_to_hub True \\\n",
        "  --output_dir ./SQuAD_BERT_el \\\n",
        "  --hub_token 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 \\\n",
        "  --version_2_with_negative True \\\n",
        "  --save_steps 10000 \\\n",
        "  --tpu_metrics_debug True\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "QA_reader_training.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}